{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd50f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cdc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS : creation of a list of vectors --> manual classification\n",
    "# IMG 53 \n",
    "y_g1_53 = np.zeros(512)\n",
    "y_g1_53[172:214] = 1\n",
    "y_g1_53[311:347] = 1\n",
    "\n",
    "# IMG 54\n",
    "y_g1_54 = np.zeros(512)\n",
    "y_g1_54[160:203] = 1\n",
    "y_g1_54[290:326] = 1\n",
    "\n",
    "# IMG 55 \n",
    "y_g1_55 = np.zeros(512)\n",
    "y_g1_55[180:226] = 1\n",
    "y_g1_55[291:332] = 1\n",
    "\n",
    "# list of vectors (one per image to provide to the function)\n",
    "label = np.concatenate((y_g1_53, y_g1_54, y_g1_55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa45f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_slices (image):\n",
    "    \n",
    "    '''\n",
    "    the function takes a 3D image and converts it to sagital slices \n",
    "    It returns a list of slices\n",
    "    \n",
    "    '''\n",
    "    shape = image.GetSize()\n",
    "    image_array = sitk.GetArrayFromImage(image)   \n",
    "    image_slices = []\n",
    "    for i in range (shape[0]):\n",
    "        sl_array = image_array[:,:,i]\n",
    "        # from image to array reverse the image up down \n",
    "        sl_array = np.flipud(sl_array)\n",
    "        image_slices.append(sl_array)\n",
    "    \n",
    "    return image_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_slices_from_paths(im_list):\n",
    "    \"\"\"\n",
    "    function to convert image paths list of numpy images of slices\n",
    "    :param im_list: list of paths to .nii.gz images\n",
    "    :return: slice_list: list of 2D numpy arrays containing image slices\n",
    "    \"\"\"\n",
    "    slice_list = []\n",
    "    # each image has to be converted in sagital slice\n",
    "    for j in range(len(im_list)):\n",
    "        # read image\n",
    "        image = sitk.ReadImage(im_list[j], sitk.sitkFloat32, imageIO=\"NiftiImageIO\")\n",
    "        # create a list of slices\n",
    "        slice_list += image_to_slices(image)\n",
    "\n",
    "    return slice_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import cv2\n",
    "def preprocess_images(image, input_size):\n",
    "    \"\"\"\n",
    "    Function to preprocess slices of image.\n",
    "    :param image: list of 2D numpy arrays that contain saggital slices of hip/femur as numpy array\n",
    "    :param input_size: input shape of image to reshape\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    input_size = (input_size[1], input_size[0]) # opencv takes y first and then x\n",
    "    image_preprocessed = [cv2.resize(slice, input_size) for slice in image]\n",
    "    image_preprocessed = [(slice - np.min(slice)) / (np.max(slice) - np.min(slice)) for slice in image_preprocessed]\n",
    "    image_preprocessed = [slice[..., np.newaxis] for slice in image_preprocessed]\n",
    "\n",
    "    print(image_preprocessed[0].max())\n",
    "\n",
    "    return image_preprocessed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras import applications, Model\n",
    "\n",
    "def GetLeNet(n_base=32, input_shape=(128, 128, 1)):\n",
    "    \"\"\"Definition of leNet tensor flow network architecture\n",
    "    \"\"\"\n",
    "    # Building the following LeNet architecture step by step\n",
    "    model = Sequential()\n",
    "    # First layer: 32 2D convolutional with size of 3by3 with \"rectified linear unit\" as activation function.\n",
    "    model.add(Conv2D(n_base, kernel_size=(3, 3), activation='relu',  strides=1, padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    # Second layer: 2D layer: pooling layer (max-pooling) with the size of 2by2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # 3rd layer: 64 2D convolutional with size of 3by3 with \"rectified linear unit\" as activation function.\n",
    "    model.add(Conv2D(2*n_base, (3, 3), activation='relu', strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    # 4th layer: pooling layer (max-pooling) with the size of 2by2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Vectorize the resulted image\n",
    "    model.add(Flatten())\n",
    "    # 5th layer: fully-connected layer (Dense) with the 128 nodes and \"rectified linear unit\" as activation function.\n",
    "    model.add(Dense(4*n_base, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "def train_classifier(im_list, labels_list):\n",
    "    \"\"\"\n",
    "\n",
    "    :param im_list: list of numpy 2D arrays slices of ct images\n",
    "    :param labels_list: list of binary label whether or not images contain structure of interest\n",
    "    :return: model: trained classifier that detects if structure is present\n",
    "             shape: shape of input\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    '''\n",
    "    train classifier\n",
    "    NB --> sagital slices of different images have different size in y direction\n",
    "    '''\n",
    "    epochs = 30\n",
    "    batch_size = 32\n",
    "    shape  = im_list[0].shape\n",
    "    images_preprocessed = np.array(preprocess_images(im_list, shape))\n",
    "\n",
    "    #x_train = np.array(images_preprocessed[0:1024])\n",
    "    #y_train = np.array(labels_list[0:1024])\n",
    "    #x_val = np.array(images_preprocessed[1024:])\n",
    "    #y_val = np.array(labels_list[1024:])\n",
    "\n",
    "    model = GetLeNet(n_base=16, input_shape=(shape[0], shape[1], 1))\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x=images_preprocessed, y=labels_list,\n",
    "              batch_size=batch_size,\n",
    "              #validation_data=(x_val, y_val),\n",
    "              epochs=epochs,verbose=1)\n",
    "\n",
    "    return model, shape\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a400e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/GROUP_images/g1_53_image.nii.gz', 'data/GROUP_images/g1_54_image.nii.gz', 'data/GROUP_images/g1_55_image.nii.gz']\n",
      "1.0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 311, 512, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 311, 512, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 155, 256, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 155, 256, 32)      4640      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 155, 256, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 77, 128, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 315392)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                20185152  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,190,209\n",
      "Trainable params: 20,190,113\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lasse/miniforge3/envs/cm2003/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2023-01-08 20:30:29.270122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 14s 244ms/step - loss: 0.8667 - accuracy: 0.8385\n",
      "Epoch 2/30\n",
      "48/48 [==============================] - 12s 256ms/step - loss: 0.2343 - accuracy: 0.8574\n",
      "Epoch 3/30\n",
      "48/48 [==============================] - 12s 246ms/step - loss: 0.2099 - accuracy: 0.8438\n",
      "Epoch 4/30\n",
      "48/48 [==============================] - 12s 248ms/step - loss: 0.1829 - accuracy: 0.8646\n",
      "Epoch 5/30\n",
      "48/48 [==============================] - 12s 246ms/step - loss: 0.1751 - accuracy: 0.8945\n",
      "Epoch 6/30\n",
      "48/48 [==============================] - 12s 246ms/step - loss: 0.1706 - accuracy: 0.9141\n",
      "Epoch 7/30\n",
      "48/48 [==============================] - 12s 247ms/step - loss: 0.1487 - accuracy: 0.9212\n",
      "Epoch 8/30\n",
      "48/48 [==============================] - 12s 246ms/step - loss: 0.1311 - accuracy: 0.9290\n",
      "Epoch 9/30\n",
      "48/48 [==============================] - 12s 246ms/step - loss: 0.1127 - accuracy: 0.9323\n",
      "Epoch 10/30\n",
      "48/48 [==============================] - 12s 259ms/step - loss: 0.1002 - accuracy: 0.9368\n",
      "Epoch 11/30\n",
      "48/48 [==============================] - 12s 248ms/step - loss: 0.0968 - accuracy: 0.9466\n",
      "Epoch 12/30\n",
      "48/48 [==============================] - 12s 251ms/step - loss: 0.1157 - accuracy: 0.9414\n",
      "Epoch 13/30\n",
      "48/48 [==============================] - 12s 250ms/step - loss: 0.1194 - accuracy: 0.9199\n",
      "Epoch 14/30\n",
      "48/48 [==============================] - 12s 248ms/step - loss: 0.1296 - accuracy: 0.9323\n",
      "Epoch 15/30\n",
      "48/48 [==============================] - 12s 253ms/step - loss: 0.2088 - accuracy: 0.9297\n",
      "Epoch 16/30\n",
      "48/48 [==============================] - 12s 251ms/step - loss: 0.1937 - accuracy: 0.9023\n",
      "Epoch 17/30\n",
      "48/48 [==============================] - 12s 244ms/step - loss: 0.1244 - accuracy: 0.9206\n",
      "Epoch 18/30\n",
      "48/48 [==============================] - 12s 248ms/step - loss: 0.0992 - accuracy: 0.9277\n",
      "Epoch 19/30\n",
      "48/48 [==============================] - 12s 244ms/step - loss: 0.0850 - accuracy: 0.9447\n",
      "Epoch 20/30\n",
      "48/48 [==============================] - 12s 245ms/step - loss: 0.1201 - accuracy: 0.9329\n",
      "Epoch 21/30\n",
      "48/48 [==============================] - 12s 244ms/step - loss: 0.1552 - accuracy: 0.9297\n",
      "Epoch 22/30\n",
      "48/48 [==============================] - 12s 246ms/step - loss: 0.0839 - accuracy: 0.9479\n",
      "Epoch 23/30\n",
      "48/48 [==============================] - 12s 245ms/step - loss: 0.0989 - accuracy: 0.9362\n",
      "Epoch 24/30\n",
      "48/48 [==============================] - 12s 247ms/step - loss: 0.0847 - accuracy: 0.9525\n",
      "Epoch 25/30\n",
      "48/48 [==============================] - 12s 244ms/step - loss: 0.0844 - accuracy: 0.9492\n",
      "Epoch 26/30\n",
      "48/48 [==============================] - 11s 239ms/step - loss: 0.0757 - accuracy: 0.9518\n",
      "Epoch 27/30\n",
      "48/48 [==============================] - 11s 239ms/step - loss: 0.0894 - accuracy: 0.9479\n",
      "Epoch 28/30\n",
      "48/48 [==============================] - 12s 242ms/step - loss: 0.0759 - accuracy: 0.9544\n",
      "Epoch 29/30\n",
      "48/48 [==============================] - 11s 239ms/step - loss: 0.0737 - accuracy: 0.9551\n",
      "Epoch 30/30\n",
      "48/48 [==============================] - 11s 240ms/step - loss: 0.0786 - accuracy: 0.9557\n"
     ]
    }
   ],
   "source": [
    "atlas_images_base = os.path.join(\"data\", \"GROUP_images\")\n",
    "files_images = os.listdir(atlas_images_base)\n",
    "atlas_images = [os.path.join(atlas_images_base, fil) for fil in files_images if \".nii\" in fil]\n",
    "print(atlas_images)\n",
    "atlas_images.sort()\n",
    "slices = get_slices_from_paths(atlas_images)\n",
    "model, shape = train_classifier(slices, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8583984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/COMMON_images_masks/common_42_image.nii.gz\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_images_base = os.path.join(\"data\", \"COMMON_images_masks\")\n",
    "files_common_images = os.listdir(common_images_base)\n",
    "files_common_images = [os.path.join(common_images_base, fil) for fil in files_common_images if \".nii\" in fil and \"image\" in fil]\n",
    "print(files_common_images[2])\n",
    "\n",
    "slices = get_slices_from_paths([files_common_images[0]])\n",
    "images_preprocessed = preprocess_images(slices, shape)\n",
    "y_pred = model.predict(np.array(images_preprocessed))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(y_pred)), y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# load group image \n",
    "im_base_dir = os.path.join(\"data\", \"GROUP_images\")\n",
    "g1_53_image = sitk.ReadImage(os.path.join(im_base_dir, \"g1_53_image.nii.gz\"), sitk.sitkFloat32, imageIO=\"NiftiImageIO\")\n",
    "g1_54_image = sitk.ReadImage(os.path.join(im_base_dir, \"g1_54_image.nii.gz\"), sitk.sitkFloat32, imageIO=\"NiftiImageIO\")\n",
    "g1_55_image = sitk.ReadImage(os.path.join(im_base_dir, \"g1_55_image.nii.gz\"), sitk.sitkFloat32, imageIO=\"NiftiImageIO\")\n",
    "\n",
    "# different size!!!!\n",
    "print(g1_55_image.GetSize())\n",
    "print(g1_54_image.GetSize())\n",
    "print(g1_53_image.GetSize())\n",
    "\n",
    "g1_53_slices = image_to_slices(g1_53_image)\n",
    "g1_54_slices = image_to_slices(g1_54_image)\n",
    "g1_55_slices = image_to_slices(g1_55_image)\n",
    "\n",
    "\n",
    "#slices = g1_53_slices + g1_54_slices + g1_55_slices\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
